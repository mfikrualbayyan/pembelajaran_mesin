{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minggu7_Distributed XGBoost with Ray.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlD/lWOlgL20oOEzrilQEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfikrualbayyan/pembelajaran_mesin/blob/main/Minggu7_Distributed_XGBoost_with_Ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xikod3lLCdY6",
        "outputId": "7ef38b38-1832-424e-9819-44edefbe8f41"
      },
      "source": [
        "pip install ray\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-1.8.0-cp37-cp37m-manylinux2014_x86_64.whl (54.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 30 kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.41.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 600 kB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.3.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.2.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray) (1.15.0)\n",
            "Installing collected packages: redis, ray\n",
            "Successfully installed ray-1.8.0 redis-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLxUmQ1eCwj3",
        "outputId": "30686ab6-9685-467e-ded5-d53d311c8c97"
      },
      "source": [
        "pip install xgboost_ray"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost_ray\n",
            "  Downloading xgboost_ray-0.1.5-py3-none-any.whl (136 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▍                             | 10 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 20 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30 kB 26.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 40 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 61 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 71 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 81 kB 32.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 92 kB 34.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 102 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 112 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 122 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 133 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 136 kB 36.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.1.5)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (0.90)\n",
            "Requirement already satisfied: wrapt>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.13.3)\n",
            "Requirement already satisfied: ray>=1.6 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.8.0)\n",
            "Requirement already satisfied: numpy<1.20,>=1.16 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (1.19.5)\n",
            "Requirement already satisfied: pyarrow<5.0.0 in /usr/local/lib/python3.7/dist-packages (from xgboost_ray) (3.0.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (1.0.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (21.2.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (7.1.2)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.13)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray>=1.6->xgboost_ray) (1.41.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray>=1.6->xgboost_ray) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost>=0.90->xgboost_ray) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->xgboost_ray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->xgboost_ray) (2018.9)\n",
            "Installing collected packages: xgboost-ray\n",
            "Successfully installed xgboost-ray-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2IhSLMvC1qQ",
        "outputId": "a5655eb9-4d43-4b1a-cefc-6021ab2195b4"
      },
      "source": [
        "pip install sklearn\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp58klvCC7gu",
        "outputId": "1cf3c057-91d8-4564-a090-5e61d0f20295"
      },
      "source": [
        "from xgboost_ray import RayDMatrix, RayParams, train\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
        "train_set = RayDMatrix(train_x, train_y)\n",
        "\n",
        "evals_result = {}\n",
        "bst = train(\n",
        "    {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    },\n",
        "    train_set,\n",
        "    evals_result=evals_result,\n",
        "    evals=[(train_set, \"train\")],\n",
        "    verbose_eval=False,\n",
        "    ray_params=RayParams(num_actors=2, cpus_per_actor=1))\n",
        "\n",
        "bst.save_model(\"model.xgb\")\n",
        "print(\"Final training error: {:.4f}\".format(\n",
        "    evals_result[\"train\"][\"error\"][-1]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "  warnings.warn(LEGACY_WARNING)\n",
            "2021-11-12 12:07:04,424\tINFO main.py:971 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
            "2021-11-12 12:07:06,660\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
            "\u001b[2m\u001b[36m(pid=286)\u001b[0m [12:07:06] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
            "\u001b[2m\u001b[36m(pid=286)\u001b[0m [12:07:06] Tree method is automatically selected to be 'approx' for distributed training.\n",
            "\u001b[2m\u001b[36m(pid=310)\u001b[0m [12:07:06] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\n",
            "\u001b[2m\u001b[36m(pid=310)\u001b[0m [12:07:06] Tree method is automatically selected to be 'approx' for distributed training.\n",
            "2021-11-12 12:07:08,153\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 4.58 seconds (1.48 pure XGBoost training time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training error: 0.0053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-m4ZQs5C-9y",
        "outputId": "35894547-1c71-468d-b7bc-0f6b9f413d11"
      },
      "source": [
        "from xgboost_ray import RayDMatrix, RayParams, predict\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import xgboost as xgb\n",
        "\n",
        "data, labels = load_breast_cancer(return_X_y=True)\n",
        "\n",
        "dpred = RayDMatrix(data, labels)\n",
        "\n",
        "bst = xgb.Booster(model_file=\"model.xgb\")\n",
        "pred_ray = predict(bst, dpred, ray_params=RayParams(num_actors=2))\n",
        "\n",
        "print(pred_ray)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "  warnings.warn(LEGACY_WARNING)\n",
            "2021-11-12 12:07:13,512\tINFO main.py:1535 -- [RayXGBoost] Created 2 remote actors.\n",
            "2021-11-12 12:07:15,677\tINFO main.py:1552 -- [RayXGBoost] Starting XGBoost prediction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.07511145 0.04715708 0.02642454 0.11464816 0.08779665 0.19609766\n",
            " 0.02642454 0.03200296 0.03968306 0.06930447 0.09290799 0.02642454\n",
            " 0.03476055 0.05490047 0.05012454 0.02642454 0.03337562 0.02642454\n",
            " 0.02642454 0.9528658  0.9751126  0.9751126  0.07511145 0.02642454\n",
            " 0.02642454 0.04102892 0.03118352 0.02642454 0.02642454 0.08779665\n",
            " 0.02642454 0.03476055 0.02642454 0.02642454 0.02642454 0.02642454\n",
            " 0.0665335  0.9690314  0.33619487 0.0696831  0.5729184  0.15662025\n",
            " 0.03451282 0.03200296 0.12301622 0.04102892 0.9751126  0.04096693\n",
            " 0.97315884 0.9234187  0.9751126  0.9751126  0.9751126  0.03059936\n",
            " 0.09855346 0.9751126  0.02642454 0.03755146 0.9751126  0.97315884\n",
            " 0.9751126  0.97315884 0.02642454 0.9751126  0.03120249 0.03120249\n",
            " 0.97315884 0.9751126  0.8630876  0.9751126  0.02642454 0.9751126\n",
            " 0.02642454 0.18486539 0.9751126  0.02642454 0.9684864  0.07511145\n",
            " 0.04528174 0.9751126  0.97315884 0.8423582  0.02642454 0.02642454\n",
            " 0.9751126  0.02642454 0.18525673 0.02642454 0.9610139  0.91992867\n",
            " 0.9637276  0.07784454 0.9476124  0.9751126  0.02642454 0.02642454\n",
            " 0.9751126  0.9690314  0.97315884 0.04415701 0.10755398 0.97315884\n",
            " 0.9751126  0.97315884 0.9751126  0.07822353 0.9541412  0.9751126\n",
            " 0.03451282 0.97315884 0.97315884 0.9505852  0.8015017  0.9751126\n",
            " 0.97315884 0.97315884 0.9690314  0.02642454 0.02642454 0.03059936\n",
            " 0.97315884 0.02642454 0.03451282 0.93471986 0.9751126  0.9751126\n",
            " 0.08796025 0.03059936 0.89851445 0.02642454 0.97315884 0.02642454\n",
            " 0.03059936 0.8943731  0.03059936 0.83710206 0.9690314  0.9751126\n",
            " 0.04825843 0.9751126  0.9751126  0.06849893 0.9751126  0.9751126\n",
            " 0.9751126  0.97315884 0.14397003 0.9537103  0.8998925  0.9543276\n",
            " 0.9751126  0.97315884 0.911794   0.9751126  0.9622466  0.9751126\n",
            " 0.02642454 0.64313    0.9751126  0.9751126  0.95592535 0.08779665\n",
            " 0.02642454 0.97315884 0.02642454 0.9657479  0.97315884 0.03337562\n",
            " 0.02642454 0.9724673  0.9751126  0.0708931  0.07511145 0.9690314\n",
            " 0.96707124 0.9751126  0.9751126  0.02642454 0.95819813 0.9690314\n",
            " 0.02642454 0.02642454 0.03337562 0.9690314  0.09398807 0.97315884\n",
            " 0.03517583 0.9751126  0.9751126  0.9751126  0.04069214 0.77108157\n",
            " 0.9434622  0.08649345 0.02786062 0.9751126  0.03120249 0.07338996\n",
            " 0.02642454 0.03118352 0.97315884 0.02642454 0.02642454 0.02642454\n",
            " 0.9622466  0.21271785 0.9751126  0.06340088 0.8858816  0.8857505\n",
            " 0.02642454 0.9751126  0.08779665 0.04224477 0.03755146 0.04096693\n",
            " 0.96730274 0.9751126  0.02642454 0.02642454 0.9751126  0.9751126\n",
            " 0.9751126  0.02642454 0.9751126  0.92772865 0.9751126  0.95374286\n",
            " 0.9610139  0.0557286  0.02642454 0.94982344 0.94982344 0.02642454\n",
            " 0.97315884 0.9751126  0.02642454 0.02863778 0.90234286 0.02642454\n",
            " 0.9751126  0.9543276  0.96730274 0.9649017  0.02642454 0.97315884\n",
            " 0.9751126  0.9469942  0.93040526 0.9751126  0.03451282 0.9751126\n",
            " 0.02642454 0.02642454 0.02642454 0.11561671 0.02642454 0.031783\n",
            " 0.03476055 0.02786062 0.02642454 0.09290799 0.02642454 0.21080676\n",
            " 0.02642454 0.02642454 0.9751126  0.9751126  0.9751126  0.9751126\n",
            " 0.9751126  0.9751126  0.02642454 0.97315884 0.04558344 0.8849121\n",
            " 0.9751126  0.03059936 0.96707124 0.9751126  0.02642454 0.9560918\n",
            " 0.02642454 0.04338858 0.9751126  0.9751126  0.96730274 0.9751126\n",
            " 0.9684864  0.9751126  0.8488096  0.7803997  0.9622466  0.9751126\n",
            " 0.9751126  0.9751126  0.9751126  0.5849058  0.92148197 0.9751126\n",
            " 0.02642454 0.9751126  0.02642454 0.9751126  0.9751126  0.9751126\n",
            " 0.9751126  0.9751126  0.9683355  0.9751126  0.9751126  0.9548208\n",
            " 0.9751126  0.9751126  0.9751126  0.9690314  0.96707124 0.02642454\n",
            " 0.968825   0.9690314  0.9751126  0.04054494 0.9265608  0.02642454\n",
            " 0.9751126  0.9751126  0.9751126  0.9751126  0.02642454 0.05098807\n",
            " 0.031783   0.9751126  0.97315884 0.9751126  0.9751126  0.02642454\n",
            " 0.9751126  0.02642454 0.9751126  0.02642454 0.89866334 0.9751126\n",
            " 0.9751126  0.02642454 0.97315884 0.9751126  0.9751126  0.9203737\n",
            " 0.97315884 0.9751126  0.9751126  0.03451282 0.031783   0.02642454\n",
            " 0.9751126  0.9751126  0.9206134  0.9751126  0.95757306 0.9751126\n",
            " 0.96707124 0.9751126  0.9751126  0.7381298  0.9751126  0.02642454\n",
            " 0.02642454 0.9751126  0.02642454 0.02642454 0.02642454 0.9523307\n",
            " 0.04687763 0.031783   0.9751126  0.8943731  0.94464666 0.94982344\n",
            " 0.9751126  0.22631724 0.9487874  0.9751126  0.9751126  0.97315884\n",
            " 0.9751126  0.08594519 0.9751126  0.9751126  0.9751126  0.02642454\n",
            " 0.9751126  0.97315884 0.02642454 0.02642454 0.97315884 0.9751126\n",
            " 0.8689699  0.9690314  0.9751126  0.9751126  0.02642454 0.9751126\n",
            " 0.9751126  0.9543276  0.9751126  0.9751126  0.8515399  0.9350665\n",
            " 0.02642454 0.9751126  0.9251611  0.9751126  0.9751126  0.860673\n",
            " 0.1858404  0.97315884 0.97315884 0.02642454 0.9751126  0.9751126\n",
            " 0.9751126  0.8970261  0.9751126  0.9609949  0.893762   0.9751126\n",
            " 0.9751126  0.9751126  0.9751126  0.96707124 0.02786062 0.9622466\n",
            " 0.02642454 0.02642454 0.9724673  0.03678946 0.9751126  0.9751126\n",
            " 0.9751126  0.9751126  0.95394206 0.02642454 0.9690314  0.9751126\n",
            " 0.04687763 0.94922996 0.02642454 0.9724673  0.9100143  0.02642454\n",
            " 0.9751126  0.02642454 0.94982344 0.9532535  0.9751126  0.9179891\n",
            " 0.935264   0.94982344 0.9751126  0.94982344 0.02642454 0.02642454\n",
            " 0.9751126  0.9751126  0.9751126  0.897271   0.96229064 0.9751126\n",
            " 0.02642454 0.9019002  0.9751126  0.9134064  0.87593234 0.94982344\n",
            " 0.9751126  0.9751126  0.81142044 0.9543276  0.9751126  0.031783\n",
            " 0.9751126  0.9476124  0.95515615 0.9543276  0.77870756 0.95053387\n",
            " 0.9548208  0.02642454 0.97315884 0.13313308 0.9751126  0.66283953\n",
            " 0.02642454 0.9751126  0.9751126  0.9008776  0.9407183  0.9751126\n",
            " 0.031783   0.02642454 0.9318961  0.04316882 0.9622466  0.02875218\n",
            " 0.9684864  0.9684864  0.9751126  0.97315884 0.9424551  0.02939261\n",
            " 0.9751126  0.96550983 0.03120249 0.93631655 0.1288219  0.9645091\n",
            " 0.02642454 0.02642454 0.9505852  0.9622466  0.97315884 0.02642454\n",
            " 0.9751126  0.9528658  0.97315884 0.97315884 0.93502516 0.9751126\n",
            " 0.950505   0.97315884 0.9751126  0.97315884 0.96634287 0.02642454\n",
            " 0.97315884 0.02642454 0.15464528 0.9293252  0.9751126  0.97315884\n",
            " 0.9751126  0.860673   0.94011134 0.9417494  0.9751126  0.9751126\n",
            " 0.9751126  0.97315884 0.9751126  0.9751126  0.9751126  0.9751126\n",
            " 0.94982344 0.9751126  0.94982344 0.88763565 0.9751126  0.94982344\n",
            " 0.9641301  0.88763565 0.92064005 0.9379563  0.02786062 0.02642454\n",
            " 0.02642454 0.02642454 0.03059936 0.02642454 0.9751126 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i3Z15nERDCyG",
        "outputId": "50e1af5f-2170-4b7d-cc52-579f5af14218"
      },
      "source": [
        "from xgboost_ray import RayDMatrix, RayParams, train\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "num_actors = 1\n",
        "num_cpus_per_actor = 1\n",
        "\n",
        "ray_params = RayParams(\n",
        "    num_actors=num_actors, cpus_per_actor=num_cpus_per_actor)\n",
        "\n",
        "def train_model(config):\n",
        "    train_x, train_y = load_breast_cancer(return_X_y=True)\n",
        "    train_set = RayDMatrix(train_x, train_y)\n",
        "\n",
        "    evals_result = {}\n",
        "    bst = train(\n",
        "        params=config,\n",
        "        dtrain=train_set,\n",
        "        evals_result=evals_result,\n",
        "        evals=[(train_set, \"train\")],\n",
        "        verbose_eval=False,\n",
        "        ray_params=ray_params)\n",
        "    bst.save_model(\"model.xgb\")\n",
        "\n",
        "from ray import tune\n",
        "\n",
        "# Specify the hyperparameter search space.\n",
        "config = {\n",
        "    \"tree_method\": \"approx\",\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    \"eta\": tune.loguniform(1e-4, 1e-1),\n",
        "    \"subsample\": tune.uniform(0.5, 1.0),\n",
        "    \"max_depth\": tune.randint(1, 9)\n",
        "}\n",
        "\n",
        "# Make sure to use the `get_tune_resources` method to set the `resources_per_trial`\n",
        "analysis = tune.run(\n",
        "    train_model,\n",
        "    config=config,\n",
        "    metric=\"train-error\",\n",
        "    mode=\"min\",\n",
        "    num_samples=4,\n",
        "    resources_per_trial=ray_params.get_tune_resources())\n",
        "print(\"Best hyperparameters\", analysis.best_config)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-11-12 12:07:30,149\tWARNING function_runner.py:564 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
            "2021-11-12 12:07:30,170\tINFO logger.py:606 -- pip install 'ray[tune]' to see TensorBoard files.\n",
            "2021-11-12 12:07:30,172\tWARNING callback.py:115 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-12 12:07:30 (running for 00:00:00.14)<br>Memory usage on this node: 1.0/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/train_model_2021-11-12_12-07-30<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_1c1ed_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00264273 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.649034</td></tr>\n",
              "<tr><td>train_model_1c1ed_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00404286 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.535964</td></tr>\n",
              "<tr><td>train_model_1c1ed_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000139259</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">   0.897684</td></tr>\n",
              "<tr><td>train_model_1c1ed_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00271159 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.891078</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m 2021-11-12 12:07:32,517\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m 2021-11-12 12:07:35,232\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-12 12:07:35 (running for 00:00:05.22)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Result logdir: /root/ray_results/train_model_2021-11-12_12-07-30<br>Number of trials: 4/4 (3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_1c1ed_00000</td><td>RUNNING </td><td>172.28.0.2:390</td><td style=\"text-align: right;\">0.00264273 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.649034</td></tr>\n",
              "<tr><td>train_model_1c1ed_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00404286 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.535964</td></tr>\n",
              "<tr><td>train_model_1c1ed_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000139259</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">   0.897684</td></tr>\n",
              "<tr><td>train_model_1c1ed_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00271159 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.891078</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_1c1ed_00000:\n",
            "  date: 2021-11-12_12-07-36\n",
            "  done: false\n",
            "  experiment_id: abd882ebd42f4390ae3305f2196771c3\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 390\n",
            "  time_since_restore: 3.8110313415527344\n",
            "  time_this_iter_s: 3.8110313415527344\n",
            "  time_total_s: 3.8110313415527344\n",
            "  timestamp: 1636718856\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.02812\n",
            "  train-logloss: 0.690853\n",
            "  training_iteration: 1\n",
            "  trial_id: 1c1ed_00000\n",
            "  \n",
            "Result for train_model_1c1ed_00000:\n",
            "  date: 2021-11-12_12-07-36\n",
            "  done: true\n",
            "  experiment_id: abd882ebd42f4390ae3305f2196771c3\n",
            "  experiment_tag: 0_eta=0.0026427,max_depth=5,subsample=0.64903\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 390\n",
            "  time_since_restore: 3.902693271636963\n",
            "  time_this_iter_s: 0.0065610408782958984\n",
            "  time_total_s: 3.902693271636963\n",
            "  timestamp: 1636718856\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.019332\n",
            "  train-logloss: 0.67107\n",
            "  training_iteration: 10\n",
            "  trial_id: 1c1ed_00000\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=390)\u001b[0m 2021-11-12 12:07:36,390\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.93 seconds (1.15 pure XGBoost training time).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[1m\u001b[36m(scheduler +37s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(scheduler +37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-11-12 12:07:38,415\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-11-12 12:07:41,031\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-12 12:07:41 (running for 00:00:11.16)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Current best trial: 1c1ed_00000 with train-error=0.019332 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.002642725212024626, 'subsample': 0.6490337971849246, 'max_depth': 5, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-12_12-07-30<br>Number of trials: 4/4 (2 PENDING, 1 RUNNING, 1 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_1c1ed_00001</td><td>RUNNING   </td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.00404286 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.535964</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_1c1ed_00002</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.000139259</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">   0.897684</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_1c1ed_00003</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.00271159 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.891078</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_1c1ed_00000</td><td>TERMINATED</td><td>172.28.0.2:390</td><td style=\"text-align: right;\">0.00264273 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.649034</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.90269</td><td style=\"text-align: right;\">        0.67107</td><td style=\"text-align: right;\">     0.019332</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_1c1ed_00001:\n",
            "  date: 2021-11-12_12-07-42\n",
            "  done: false\n",
            "  experiment_id: 1b285b46e2bc42208d2a365c27695af9\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 494\n",
            "  time_since_restore: 3.7036802768707275\n",
            "  time_this_iter_s: 3.7036802768707275\n",
            "  time_total_s: 3.7036802768707275\n",
            "  timestamp: 1636718862\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.049209\n",
            "  train-logloss: 0.689701\n",
            "  training_iteration: 1\n",
            "  trial_id: 1c1ed_00001\n",
            "  \n",
            "Result for train_model_1c1ed_00001:\n",
            "  date: 2021-11-12_12-07-42\n",
            "  done: true\n",
            "  experiment_id: 1b285b46e2bc42208d2a365c27695af9\n",
            "  experiment_tag: 1_eta=0.0040429,max_depth=7,subsample=0.53596\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 494\n",
            "  time_since_restore: 3.780517339706421\n",
            "  time_this_iter_s: 0.005498409271240234\n",
            "  time_total_s: 3.780517339706421\n",
            "  timestamp: 1636718862\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.022847\n",
            "  train-logloss: 0.660387\n",
            "  training_iteration: 10\n",
            "  trial_id: 1c1ed_00001\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=494)\u001b[0m 2021-11-12 12:07:42,194\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.83 seconds (1.16 pure XGBoost training time).\n",
            "2021-11-12 12:07:42,700\tWARNING worker.py:1228 -- The actor or task with ID ffffffffffffffff9b82dec27f09b3feb7dfae5a01000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
            "Required resources for this actor or task: {CPU_group_0_a48f2f1b4a9457864c2d977e86c2755c: 1.000000}, {CPU_group_a48f2f1b4a9457864c2d977e86c2755c: 1.000000}\n",
            "Available resources on this node: {0.000000/2.000000 CPU, 385689240.039062 GiB/385689240.039062 GiB memory, 192844619.970703 GiB/192844619.970703 GiB object_store_memory, 1000.000000/1000.000000 bundle_group_0_a48f2f1b4a9457864c2d977e86c2755c, 1000.000000/1000.000000 bundle_group_1_a48f2f1b4a9457864c2d977e86c2755c, 0.000000/1.000000 CPU_group_0_a48f2f1b4a9457864c2d977e86c2755c, 1.000000/1.000000 node:172.28.0.2, 1.000000/1.000000 CPU_group_1_a48f2f1b4a9457864c2d977e86c2755c, 1.000000/2.000000 CPU_group_a48f2f1b4a9457864c2d977e86c2755c, 2000.000000/2000.000000 bundle_group_a48f2f1b4a9457864c2d977e86c2755c}\n",
            "In total there are 0 pending tasks and 1 pending actors on this node.\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m 2021-11-12 12:07:44,274\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m 2021-11-12 12:07:46,995\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-12 12:07:47 (running for 00:00:17.05)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Current best trial: 1c1ed_00000 with train-error=0.019332 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.002642725212024626, 'subsample': 0.6490337971849246, 'max_depth': 5, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-12_12-07-30<br>Number of trials: 4/4 (1 PENDING, 1 RUNNING, 2 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_1c1ed_00002</td><td>RUNNING   </td><td>172.28.0.2:598</td><td style=\"text-align: right;\">0.000139259</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">   0.897684</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_1c1ed_00003</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.00271159 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.891078</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_1c1ed_00000</td><td>TERMINATED</td><td>172.28.0.2:390</td><td style=\"text-align: right;\">0.00264273 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.649034</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.90269</td><td style=\"text-align: right;\">       0.67107 </td><td style=\"text-align: right;\">     0.019332</td></tr>\n",
              "<tr><td>train_model_1c1ed_00001</td><td>TERMINATED</td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.00404286 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.535964</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.78052</td><td style=\"text-align: right;\">       0.660387</td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_1c1ed_00002:\n",
            "  date: 2021-11-12_12-07-48\n",
            "  done: false\n",
            "  experiment_id: 69e8a77c778c47f29e3da7200aea5a10\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 598\n",
            "  time_since_restore: 3.8117454051971436\n",
            "  time_this_iter_s: 3.8117454051971436\n",
            "  time_total_s: 3.8117454051971436\n",
            "  timestamp: 1636718868\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.035149\n",
            "  train-logloss: 0.693028\n",
            "  training_iteration: 1\n",
            "  trial_id: 1c1ed_00002\n",
            "  \n",
            "Result for train_model_1c1ed_00002:\n",
            "  date: 2021-11-12_12-07-48\n",
            "  done: true\n",
            "  experiment_id: 69e8a77c778c47f29e3da7200aea5a10\n",
            "  experiment_tag: 2_eta=0.00013926,max_depth=6,subsample=0.89768\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 598\n",
            "  time_since_restore: 3.8922457695007324\n",
            "  time_this_iter_s: 0.005303621292114258\n",
            "  time_total_s: 3.8922457695007324\n",
            "  timestamp: 1636718868\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.010545\n",
            "  train-logloss: 0.691921\n",
            "  training_iteration: 10\n",
            "  trial_id: 1c1ed_00002\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=598)\u001b[0m 2021-11-12 12:07:48,155\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.93 seconds (1.16 pure XGBoost training time).\n",
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:166: UserWarning: You are using `xgboost_ray` with a legacy XGBoost version (version 0.90). While we try to support older XGBoost versions, please note that this library is only fully tested and supported for XGBoost >= 1.4. Please consider upgrading your XGBoost version (`pip install -U xgboost`).\n",
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m   warnings.warn(LEGACY_WARNING)\n",
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m /usr/local/lib/python3.7/dist-packages/xgboost_ray/main.py:422: UserWarning: `num_actors` in `ray_params` is smaller than 2 (1). XGBoost will NOT be distributed!\n",
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m   f\"`num_actors` in `ray_params` is smaller than 2 \"\n",
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m 2021-11-12 12:07:50,238\tINFO main.py:971 -- [RayXGBoost] Created 1 new actors (1 total actors). Waiting until actors are ready for training.\n",
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m 2021-11-12 12:07:52,857\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-12 12:07:53 (running for 00:00:23.03)<br>Memory usage on this node: 1.4/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Current best trial: 1c1ed_00002 with train-error=0.010545 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.00013925851592098862, 'subsample': 0.8976841634935044, 'max_depth': 6, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-12_12-07-30<br>Number of trials: 4/4 (1 RUNNING, 3 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_1c1ed_00003</td><td>RUNNING   </td><td>172.28.0.2:704</td><td style=\"text-align: right;\">0.00271159 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.891078</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
              "<tr><td>train_model_1c1ed_00000</td><td>TERMINATED</td><td>172.28.0.2:390</td><td style=\"text-align: right;\">0.00264273 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.649034</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.90269</td><td style=\"text-align: right;\">       0.67107 </td><td style=\"text-align: right;\">     0.019332</td></tr>\n",
              "<tr><td>train_model_1c1ed_00001</td><td>TERMINATED</td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.00404286 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.535964</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.78052</td><td style=\"text-align: right;\">       0.660387</td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "<tr><td>train_model_1c1ed_00002</td><td>TERMINATED</td><td>172.28.0.2:598</td><td style=\"text-align: right;\">0.000139259</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">   0.897684</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.89225</td><td style=\"text-align: right;\">       0.691921</td><td style=\"text-align: right;\">     0.010545</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for train_model_1c1ed_00003:\n",
            "  date: 2021-11-12_12-07-53\n",
            "  done: false\n",
            "  experiment_id: 2405bad56d1548efb35cdd8a613fafb2\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 704\n",
            "  time_since_restore: 3.7112832069396973\n",
            "  time_this_iter_s: 3.7112832069396973\n",
            "  time_total_s: 3.7112832069396973\n",
            "  timestamp: 1636718873\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.031634\n",
            "  train-logloss: 0.690786\n",
            "  training_iteration: 1\n",
            "  trial_id: 1c1ed_00003\n",
            "  \n",
            "Result for train_model_1c1ed_00003:\n",
            "  date: 2021-11-12_12-07-53\n",
            "  done: true\n",
            "  experiment_id: 2405bad56d1548efb35cdd8a613fafb2\n",
            "  experiment_tag: 3_eta=0.0027116,max_depth=7,subsample=0.89108\n",
            "  hostname: 8f78660d33d7\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  pid: 704\n",
            "  time_since_restore: 3.775371789932251\n",
            "  time_this_iter_s: 0.005177021026611328\n",
            "  time_total_s: 3.775371789932251\n",
            "  timestamp: 1636718873\n",
            "  timesteps_since_restore: 0\n",
            "  train-error: 0.008787\n",
            "  train-logloss: 0.669765\n",
            "  training_iteration: 10\n",
            "  trial_id: 1c1ed_00003\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Current time: 2021-11-12 12:07:54 (running for 00:00:23.87)<br>Memory usage on this node: 1.1/12.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.36 GiB heap, 0.0/3.68 GiB objects<br>Current best trial: 1c1ed_00003 with train-error=0.008787 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.002711587778961428, 'subsample': 0.8910776376722229, 'max_depth': 7, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /root/ray_results/train_model_2021-11-12_12-07-30<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_1c1ed_00000</td><td>TERMINATED</td><td>172.28.0.2:390</td><td style=\"text-align: right;\">0.00264273 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">   0.649034</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.90269</td><td style=\"text-align: right;\">       0.67107 </td><td style=\"text-align: right;\">     0.019332</td></tr>\n",
              "<tr><td>train_model_1c1ed_00001</td><td>TERMINATED</td><td>172.28.0.2:494</td><td style=\"text-align: right;\">0.00404286 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.535964</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.78052</td><td style=\"text-align: right;\">       0.660387</td><td style=\"text-align: right;\">     0.022847</td></tr>\n",
              "<tr><td>train_model_1c1ed_00002</td><td>TERMINATED</td><td>172.28.0.2:598</td><td style=\"text-align: right;\">0.000139259</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">   0.897684</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.89225</td><td style=\"text-align: right;\">       0.691921</td><td style=\"text-align: right;\">     0.010545</td></tr>\n",
              "<tr><td>train_model_1c1ed_00003</td><td>TERMINATED</td><td>172.28.0.2:704</td><td style=\"text-align: right;\">0.00271159 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">   0.891078</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         3.77537</td><td style=\"text-align: right;\">       0.669765</td><td style=\"text-align: right;\">     0.008787</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=704)\u001b[0m 2021-11-12 12:07:54,016\tINFO main.py:1498 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 3.83 seconds (1.15 pure XGBoost training time).\n",
            "2021-11-12 12:07:54,182\tINFO tune.py:630 -- Total run time: 24.04 seconds (23.84 seconds for the tuning loop).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters {'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.002711587778961428, 'subsample': 0.8910776376722229, 'max_depth': 7}\n"
          ]
        }
      ]
    }
  ]
}